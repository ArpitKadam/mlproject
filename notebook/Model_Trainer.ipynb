{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, mean_absolute_error, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor , GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Arpit Kadam\\\\Desktop\\\\mlproject\\\\data\\\\stud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test_preparation_course  math_score  reading_score  writing_score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>218</td>\n",
       "      <td>72.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>247</td>\n",
       "      <td>82.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>278</td>\n",
       "      <td>92.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>148</td>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>229</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test_preparation_course  math_score  reading_score  writing_score  \\\n",
       "0                    none          72             72             74   \n",
       "1               completed          69             90             88   \n",
       "2                    none          90             95             93   \n",
       "3                    none          47             57             44   \n",
       "4                    none          76             78             75   \n",
       "\n",
       "   total_score  average_score  \n",
       "0          218      72.666667  \n",
       "1          247      82.333333  \n",
       "2          278      92.666667  \n",
       "3          148      49.333333  \n",
       "4          229      76.333333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_score'] = df['math_score'] + df['reading_score'] + df['writing_score']\n",
    "df['average_score'] = df['total_score'] / 3\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>218</td>\n",
       "      <td>72.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>247</td>\n",
       "      <td>82.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>278</td>\n",
       "      <td>92.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>148</td>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>229</td>\n",
       "      <td>76.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  race_ethnicity  parental_level_of_education  lunch  \\\n",
       "0       0               1                            1      1   \n",
       "1       0               2                            4      1   \n",
       "2       0               1                            3      1   \n",
       "3       1               0                            0      0   \n",
       "4       1               2                            4      1   \n",
       "\n",
       "   test_preparation_course  math_score  reading_score  writing_score  \\\n",
       "0                        1          72             72             74   \n",
       "1                        0          69             90             88   \n",
       "2                        1          90             95             93   \n",
       "3                        1          47             57             44   \n",
       "4                        1          76             78             75   \n",
       "\n",
       "   total_score  average_score  \n",
       "0          218      72.666667  \n",
       "1          247      82.333333  \n",
       "2          278      92.666667  \n",
       "3          148      49.333333  \n",
       "4          229      76.333333  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Performing Label Encoding\n",
    "categorical_columns =['gender','race_ethnicity','parental_level_of_education','lunch','test_preparation_course']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df[column] = encoder.fit_transform(df[column])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing Outliers, Shape:  (1000, 10)\n",
      "After removing Outliers, Shape:  (988, 10)\n"
     ]
    }
   ],
   "source": [
    "## Removing Outliers\n",
    "\n",
    "def remove_outliers(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for column in columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "numerical_columns = ['math_score', 'reading_score', 'writing_score', 'total_score', 'average_score']\n",
    "df_clean = remove_outliers(df, numerical_columns)\n",
    "print(\"Before removing Outliers, Shape: \", df.shape)\n",
    "print(\"After removing Outliers, Shape: \", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.96811926 -1.02167248 -0.80607157 ...  0.16840602  0.37424098\n",
      "   0.32393971]\n",
      " [-0.96811926 -0.15670898  0.83485984 ...  1.45323338  1.33856684\n",
      "   1.0374089 ]\n",
      " [-0.96811926 -1.02167248  0.2878827  ...  1.81012987  1.68296893\n",
      "   1.80008287]\n",
      " ...\n",
      " [-0.96811926 -0.15670898 -0.25909443 ...  0.09702672 -0.24568279\n",
      "  -0.24191516]\n",
      " [-0.96811926  0.70825453  0.83485984 ...  0.5966818   0.58088224\n",
      "   0.44695164]\n",
      " [-0.96811926  0.70825453  0.83485984 ...  1.16771619  1.200806\n",
      "   1.08661368]]\n",
      "0      218\n",
      "1      247\n",
      "2      278\n",
      "3      148\n",
      "4      229\n",
      "      ... \n",
      "995    282\n",
      "996    172\n",
      "997    195\n",
      "998    223\n",
      "999    249\n",
      "Name: total_score, Length: 988, dtype: int64\n",
      "X Shape:  (988, 9)\n",
      "Y Shape:  (988,)\n"
     ]
    }
   ],
   "source": [
    "## Performing Standatdization\n",
    "\n",
    "x = df_clean.drop(['total_score'], axis=1)\n",
    "y = df_clean['total_score']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "print(x)\n",
    "print(y)\n",
    "print(\"X Shape: \", x.shape)\n",
    "print(\"Y Shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape:  (790, 9)\n",
      "X Test Shape:  (198, 9)\n",
      "Y Train Shape:  (790,)\n",
      "Y Test Shape:  (198,)\n"
     ]
    }
   ],
   "source": [
    "## Splitting the data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(\"X Train Shape: \", x_train.shape)\n",
    "print(\"X Test Shape: \", x_test.shape)\n",
    "print(\"Y Train Shape: \", y_train.shape)\n",
    "print(\"Y Test Shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def perform_hyperparameter_tuning(X_train, y_train):\n",
    "    models = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(),\n",
    "            'params': {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'solver': ['liblinear', 'lbfgs'],\n",
    "                'max_iter': [100, 200]\n",
    "            }\n",
    "        },\n",
    "        'Lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            }\n",
    "        },\n",
    "        'Ridge': {\n",
    "            'model': Ridge(),\n",
    "            'params': {\n",
    "                'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "            }\n",
    "        },\n",
    "        'ElasticNet': {\n",
    "            'model': ElasticNet(),\n",
    "            'params': {\n",
    "                'alpha'     : [0.1,1,10,0.01],\n",
    "                'l1_ratio'  :  np.arange(0.40,1.00,0.10),\n",
    "                'tol'       : [0.0001,0.001]\n",
    "            }\n",
    "        },\n",
    "        'RandomForestRegressor': {\n",
    "            'model': RandomForestRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'max_depth': [None, 10],\n",
    "                'min_samples_split': [2, 5]\n",
    "            }\n",
    "        },\n",
    "        'AdaBoostRegressor': {\n",
    "            'model': AdaBoostRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'learning_rate': [0.01, 0.1, 1]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoostingRegressor': {\n",
    "            'model': GradientBoostingRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [50, 100],\n",
    "                'learning_rate': [0.01, 0.1, 1],\n",
    "                'max_depth': [3, 5, 7]\n",
    "            }\n",
    "        },\n",
    "        'DecisionTreeRegressor': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 5, 10]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, config in models.items():\n",
    "        print(f\"Tuning {model_name}...\")\n",
    "        grid_search = GridSearchCV(config['model'], config['params'], cv=5, scoring='r2', n_jobs=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(x_train)\n",
    "        mae = mean_absolute_error(y_train, y_pred)\n",
    "        mse = mean_squared_error(y_train, y_pred)\n",
    "        results[model_name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "        }\n",
    "        print(f\"{model_name} Best Params: {grid_search.best_params_}\")\n",
    "        print(f\"{model_name} Best Score: {grid_search.best_score_}\\n\")\n",
    "        print(f\"{model_name} Mean Absolute Error: {mae}\")\n",
    "        print(f\"{model_name} Mean Squared Error: {mse}\\n\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Best Params: {'C': 10, 'max_iter': 100, 'solver': 'lbfgs'}\n",
      "LogisticRegression Best Score: 0.9257620143127696\n",
      "\n",
      "LogisticRegression Mean Absolute Error: 5.262025316455696\n",
      "LogisticRegression Mean Squared Error: 59.28227848101266\n",
      "\n",
      "Tuning Lasso...\n",
      "Lasso Best Params: {'alpha': 0.1}\n",
      "Lasso Best Score: 0.9999934515877282\n",
      "\n",
      "Lasso Mean Absolute Error: 0.08241568713622886\n",
      "Lasso Mean Squared Error: 0.010397620146434866\n",
      "\n",
      "Tuning Ridge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+02, tolerance: 1.038e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+02, tolerance: 9.925e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+02, tolerance: 1.011e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+02, tolerance: 1.058e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+02, tolerance: 1.051e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Arpit Kadam\\Desktop\\mlproject\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+02, tolerance: 1.288e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Best Params: {'alpha': 0.1}\n",
      "Ridge Best Score: 0.9999999974222027\n",
      "\n",
      "Ridge Mean Absolute Error: 0.0012995054765310395\n",
      "Ridge Mean Squared Error: 2.5910000610109936e-06\n",
      "\n",
      "Tuning ElasticNet...\n",
      "ElasticNet Best Params: {'alpha': 0.01, 'l1_ratio': 0.8999999999999999, 'tol': 0.0001}\n",
      "ElasticNet Best Score: 0.9999997712402555\n",
      "\n",
      "ElasticNet Mean Absolute Error: 0.015429741739596114\n",
      "ElasticNet Mean Squared Error: 0.0003622816630901358\n",
      "\n",
      "Tuning RandomForestRegressor...\n",
      "RandomForestRegressor Best Params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForestRegressor Best Score: 0.9998359245781924\n",
      "\n",
      "RandomForestRegressor Mean Absolute Error: 0.05948101265822664\n",
      "RandomForestRegressor Mean Squared Error: 0.03782367088607584\n",
      "\n",
      "Tuning AdaBoostRegressor...\n",
      "AdaBoostRegressor Best Params: {'learning_rate': 1, 'n_estimators': 100}\n",
      "AdaBoostRegressor Best Score: 0.9966454404334651\n",
      "\n",
      "AdaBoostRegressor Mean Absolute Error: 2.413149089827401\n",
      "AdaBoostRegressor Mean Squared Error: 8.991538618738357\n",
      "\n",
      "Tuning GradientBoostingRegressor...\n",
      "GradientBoostingRegressor Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "GradientBoostingRegressor Best Score: 0.9999190299880745\n",
      "\n",
      "GradientBoostingRegressor Mean Absolute Error: 0.1689398087837191\n",
      "GradientBoostingRegressor Mean Squared Error: 0.044402642965340855\n",
      "\n",
      "Tuning DecisionTreeRegressor...\n",
      "DecisionTreeRegressor Best Params: {'max_depth': None, 'min_samples_split': 5}\n",
      "DecisionTreeRegressor Best Score: 0.9998033749813112\n",
      "\n",
      "DecisionTreeRegressor Mean Absolute Error: 0.05611814345991552\n",
      "DecisionTreeRegressor Mean Squared Error: 0.04609704641350212\n",
      "\n",
      "LogisticRegression: Best Params: {'C': 10, 'max_iter': 100, 'solver': 'lbfgs'}, Best Score: 0.9257620143127696\n",
      "Lasso: Best Params: {'alpha': 0.1}, Best Score: 0.9999934515877282\n",
      "Ridge: Best Params: {'alpha': 0.1}, Best Score: 0.9999999974222027\n",
      "ElasticNet: Best Params: {'alpha': 0.01, 'l1_ratio': 0.8999999999999999, 'tol': 0.0001}, Best Score: 0.9999997712402555\n",
      "RandomForestRegressor: Best Params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}, Best Score: 0.9998359245781924\n",
      "AdaBoostRegressor: Best Params: {'learning_rate': 1, 'n_estimators': 100}, Best Score: 0.9966454404334651\n",
      "GradientBoostingRegressor: Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}, Best Score: 0.9999190299880745\n",
      "DecisionTreeRegressor: Best Params: {'max_depth': None, 'min_samples_split': 5}, Best Score: 0.9998033749813112\n"
     ]
    }
   ],
   "source": [
    "# Example: Call the function with your data\n",
    "results = perform_hyperparameter_tuning(x_train, y_train)\n",
    "\n",
    "# Print results\n",
    "for model, info in results.items():\n",
    "    print(f\"{model}: Best Params: {info['best_params']}, Best Score: {info['best_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogisticRegression': {'best_params': {'C': 10, 'max_iter': 100, 'solver': 'lbfgs'}, 'best_score': 0.9257620143127696, 'mse': 59.28227848101266, 'mae': 5.262025316455696}, 'Lasso': {'best_params': {'alpha': 0.1}, 'best_score': 0.9999934515877282, 'mse': 0.010397620146434866, 'mae': 0.08241568713622886}, 'Ridge': {'best_params': {'alpha': 0.1}, 'best_score': 0.9999999974222027, 'mse': 2.5910000610109936e-06, 'mae': 0.0012995054765310395}, 'ElasticNet': {'best_params': {'alpha': 0.01, 'l1_ratio': 0.8999999999999999, 'tol': 0.0001}, 'best_score': 0.9999997712402555, 'mse': 0.0003622816630901358, 'mae': 0.015429741739596114}, 'RandomForestRegressor': {'best_params': {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}, 'best_score': 0.9998359245781924, 'mse': 0.03782367088607584, 'mae': 0.05948101265822664}, 'AdaBoostRegressor': {'best_params': {'learning_rate': 1, 'n_estimators': 100}, 'best_score': 0.9966454404334651, 'mse': 8.991538618738357, 'mae': 2.413149089827401}, 'GradientBoostingRegressor': {'best_params': {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}, 'best_score': 0.9999190299880745, 'mse': 0.044402642965340855, 'mae': 0.1689398087837191}, 'DecisionTreeRegressor': {'best_params': {'max_depth': None, 'min_samples_split': 5}, 'best_score': 0.9998033749813112, 'mse': 0.04609704641350212, 'mae': 0.05611814345991552}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 10, 'max_iter': 100, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.925762</td>\n",
       "      <td>5.262025</td>\n",
       "      <td>59.282278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.082416</td>\n",
       "      <td>0.010398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 0.8999999999999999...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>0.999836</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.037824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 100}</td>\n",
       "      <td>0.996645</td>\n",
       "      <td>2.413149</td>\n",
       "      <td>8.991539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.168940</td>\n",
       "      <td>0.044403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 5}</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.056118</td>\n",
       "      <td>0.046097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Name  \\\n",
       "0         LogisticRegression   \n",
       "1                      Lasso   \n",
       "2                      Ridge   \n",
       "3                 ElasticNet   \n",
       "4      RandomForestRegressor   \n",
       "5          AdaBoostRegressor   \n",
       "6  GradientBoostingRegressor   \n",
       "7      DecisionTreeRegressor   \n",
       "\n",
       "                                         Best Params  R2 Score       MAE  \\\n",
       "0      {'C': 10, 'max_iter': 100, 'solver': 'lbfgs'}  0.925762  5.262025   \n",
       "1                                     {'alpha': 0.1}  0.999993  0.082416   \n",
       "2                                     {'alpha': 0.1}  1.000000  0.001300   \n",
       "3  {'alpha': 0.01, 'l1_ratio': 0.8999999999999999...  1.000000  0.015430   \n",
       "4  {'max_depth': 10, 'min_samples_split': 2, 'n_e...  0.999836  0.059481   \n",
       "5          {'learning_rate': 1, 'n_estimators': 100}  0.996645  2.413149   \n",
       "6  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...  0.999919  0.168940   \n",
       "7        {'max_depth': None, 'min_samples_split': 5}  0.999803  0.056118   \n",
       "\n",
       "         MSE  \n",
       "0  59.282278  \n",
       "1   0.010398  \n",
       "2   0.000003  \n",
       "3   0.000362  \n",
       "4   0.037824  \n",
       "5   8.991539  \n",
       "6   0.044403  \n",
       "7   0.046097  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_results_dataframe(results):\n",
    "    # Initialize an empty list to store rows\n",
    "    rows = []\n",
    "    \n",
    "    for model_name, model_info in results.items():\n",
    "        row = {\n",
    "            \"Model Name\": model_name,\n",
    "            \"Best Params\": model_info.get('best_params'),\n",
    "            \"R2 Score\": model_info.get('best_score'),\n",
    "            \"MAE\": model_info.get('mae'),\n",
    "            \"MSE\": model_info.get('mse'),\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    # Create a DataFrame from the rows\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `results` is the dictionary containing your hyperparameter tuning results\n",
    "# Add MAE and MSE calculations for each model during tuning before passing results to this function.\n",
    "\n",
    "results_df = create_results_dataframe(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
